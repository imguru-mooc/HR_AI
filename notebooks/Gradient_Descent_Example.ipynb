{"cells": [{"cell_type": "markdown", "metadata": {}, "source": ["# Gradient Descent \uc2e4\uc2b5\n", "\n", "\uae30\ubcf8\uc801\uc778 \uacbd\uc0ac \ud558\uac15\ubc95(Gradient Descent)\uc744 \uc774\uc6a9\ud55c \uc120\ud615 \ud68c\uadc0 \uc2e4\uc2b5\uc785\ub2c8\ub2e4."]}, {"cell_type": "code", "execution_count": 1, "metadata": {}, "outputs": [], "source": ["# \ub77c\uc774\ube0c\ub7ec\ub9ac \ubd88\ub7ec\uc624\uae30\n", "import numpy as np\n", "import matplotlib.pyplot as plt"]}, {"cell_type": "code", "execution_count": 2, "metadata": {}, "outputs": [], "source": ["# \ub370\uc774\ud130 \uc0dd\uc131 (y = 4 + 3x + \ub178\uc774\uc988)\n", "np.random.seed(0)\n", "X = 2 * np.random.rand(100, 1)\n", "y = 4 + 3 * X + np.random.randn(100, 1)\n", "\n", "plt.scatter(X, y)\n", "plt.xlabel(\"X\")\n", "plt.ylabel(\"y\")\n", "plt.title(\"Generated Data\")\n", "plt.show()"]}, {"cell_type": "code", "execution_count": 3, "metadata": {}, "outputs": [], "source": ["# \ube44\uc6a9 \ud568\uc218 (Mean Squared Error)\n", "def compute_cost(X, y, theta):\n", "    m = len(y)\n", "    predictions = X.dot(theta)\n", "    cost = (1/2*m) * np.sum(np.square(predictions - y))\n", "    return cost"]}, {"cell_type": "code", "execution_count": 4, "metadata": {}, "outputs": [], "source": ["# \uacbd\uc0ac \ud558\uac15\ubc95 \ud568\uc218\n", "def gradient_descent(X, y, theta, learning_rate, iterations):\n", "    m = len(y)\n", "    cost_history = []\n", "\n", "    for _ in range(iterations):\n", "        prediction = np.dot(X, theta)\n", "        error = prediction - y\n", "        gradients = (1/m) * X.T.dot(error)\n", "        theta = theta - learning_rate * gradients\n", "        cost = compute_cost(X, y, theta)\n", "        cost_history.append(cost)\n", "\n", "    return theta, cost_history"]}, {"cell_type": "code", "execution_count": 5, "metadata": {}, "outputs": [], "source": ["# \ub370\uc774\ud130 \uc900\ube44 (bias term \ucd94\uac00)\n", "X_b = np.c_[np.ones((100, 1)), X]\n", "theta = np.random.randn(2, 1)  # \ucd08\uae30 \uac00\uc911\uce58 (\ub79c\ub364)"]}, {"cell_type": "code", "execution_count": 6, "metadata": {}, "outputs": [], "source": ["# \ud558\uc774\ud37c\ud30c\ub77c\ubbf8\ud130 \uc124\uc815 \ubc0f Gradient Descent \uc2e4\ud589\n", "learning_rate = 0.1\n", "iterations = 100\n", "\n", "theta_final, cost_history = gradient_descent(X_b, y, theta, learning_rate, iterations)\n", "\n", "print(\"\ucd5c\uc885 \ud30c\ub77c\ubbf8\ud130 (theta):\")\n", "print(theta_final)"]}, {"cell_type": "code", "execution_count": 7, "metadata": {}, "outputs": [], "source": ["# \ube44\uc6a9 \ud568\uc218 \uc2dc\uac01\ud654\n", "plt.plot(range(iterations), cost_history, 'b-')\n", "plt.xlabel(\"Iterations\")\n", "plt.ylabel(\"Cost (MSE)\")\n", "plt.title(\"Cost Reduction Over Iterations\")\n", "plt.show()"]}, {"cell_type": "code", "execution_count": 8, "metadata": {}, "outputs": [], "source": ["# \ud68c\uadc0\uc120 \uc2dc\uac01\ud654\n", "plt.scatter(X, y)\n", "plt.plot(X, X_b.dot(theta_final), color='red')\n", "plt.xlabel(\"X\")\n", "plt.ylabel(\"y\")\n", "plt.title(\"Regression Line after Gradient Descent\")\n", "plt.show()"]}], "metadata": {"kernelspec": {"display_name": "Python 3", "language": "python", "name": "python3"}, "language_info": {"name": "python", "version": "3.9"}}, "nbformat": 4, "nbformat_minor": 5}